# -*- coding: utf-8 -*-
"""ReQuEST_Pytorch_lightning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k8WprvAMnHmKK63QsA9BT3RYPI9UrGEH
"""

class OverrideEpochStepCallback(Callback):
    def __init__(self) -> None:
        super().__init__()

    def on_train_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):
        self._log_step_as_current_epoch(trainer, pl_module)

    def on_test_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):
        self._log_step_as_current_epoch(trainer, pl_module)

    def on_validation_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):
        self._log_step_as_current_epoch(trainer, pl_module)

    def _log_step_as_current_epoch(self, trainer: pl.Trainer, pl_module: pl.LightningModule):
        pl_module.log("step", trainer.current_epoch + 1)


class LitReQuEST(pl.LightningModule):
    def __init__(self, hparams):
      super(LitReQuEST, self).__init__()
      self.save_hyperparameters()
      self.Model = hparams['Model']
      self.tokenizer = hparams['tokenizer']
      self.RQE_Loss_Func = hparams['CELoss']
      self.SUM_Loss_Func = copy.deepcopy(hparams['MixedLoss'])
      self.TG_Loss_Func = copy.deepcopy(hparams['MixedLoss'])
      self.FreezeEnc = hparams['FreezeLayers'][0]
      self.FreezeDec = hparams['FreezeLayers'][1]
      self.Coefficient = hparams['Coefficient']
      self.max_epochs = hparams['max_epochs']
      self.warmup = hparams['warmup']
      self.num_train_batches = hparams['num_train_batches']
      self.opt_epsilon = hparams['epsilon']
      self.Micro_iter= 3

      self.automatic_optimization = False
      self.opt1, self.opt2, self.opt3, self.opt4,\
       self.opt5 = self.configure_optimizers()
      self.scheduler_Encoder = self.configure_scheduler(self.opt2)
      self.scheduler_Decoder = self.configure_scheduler(self.opt3)

      rqe_metrics = MetricCollection([
            Accuracy(task="binary", num_classes=2),
            F1Score(task="binary", num_classes=2)
        ])
      rouge_keys = ("rouge1", "rouge2", "rougeL")
      sum_metrics = MetricCollection([
            ROUGEScore(rouge_keys=rouge_keys),
            BERTScore()
        ])
      tg_metrics = MetricCollection([
            ROUGEScore(rouge_keys=rouge_keys),
            BERTScore()
        ])

      self.test_rqe_metrics = rqe_metrics.clone(prefix='test_')
      self.test_sum_metrics = sum_metrics.clone(prefix='test_')
      self.test_tg_metrics = tg_metrics.clone(prefix='test_')


    def forward(self, EncoderRQE_input_ids = None,
                EncoderRQE_attention = None,
                EncoderSUM_input_ids = None,
                EncoderSUM_attention_mask = None,
                EncoderTG_input_ids = None,
                EncoderTG_attention_mask = None,
                DecoderSUM_input_ids = None,
                DecoderSUM_attention_mask = None,
                DecoderTG_input_ids = None,
                DecoderTG_attention_mask = None,
                output_attentions = None,
                output_hidden_states = None,
                encoder_outputs = None,
                SUM_labels = None,
                TG_labels = None,
                past_key_values = None,
                head_mask = None,
                decoder_head_mask = None,
                cross_attn_head_mask = None,
                inputs_embeds = None,
                decoder_inputs_embeds = None,
                use_cache = None,
                return_dict = None,
                decoder_task = None):
        return self.Model(
            EncoderRQE_input_ids, EncoderRQE_attention,
            EncoderSUM_input_ids, EncoderSUM_attention_mask,
            EncoderTG_input_ids, EncoderTG_attention_mask,
            DecoderSUM_input_ids, DecoderSUM_attention_mask,
            DecoderTG_input_ids, DecoderTG_attention_mask,
            output_attentions, output_hidden_states,
            encoder_outputs, SUM_labels, TG_labels,
            past_key_values, head_mask, decoder_head_mask,
            cross_attn_head_mask, inputs_embeds,
            decoder_inputs_embeds, use_cache, return_dict,
            decoder_task)


    def training_step(self, batch, batch_idx):
      Q1Q2_input_ids, Q1Q2_attention, Q1Tags_input_ids, Q1Tags_attention,\
        Q1_input_ids, Q1_attention, GoldSummary_input_ids, GoldTags_input_ids,\
          Pair_Labels = batch

      self.Model.Freeze_Parameters(self.FreezeDec, self.FreezeEnc)
      for iter in range(0, self.Micro_iter):
        self.opt1.zero_grad()
        self.opt4.zero_grad()
        self.opt5.zero_grad()
        self.opt3.zero_grad()
        self.opt2.zero_grad()

        Model_Output = self.Model(
            EncoderRQE_input_ids = Q1Q2_input_ids,
            EncoderRQE_attention = Q1Q2_attention,
            EncoderSUM_input_ids = Q1Tags_input_ids,
            EncoderSUM_attention_mask = Q1Tags_attention,
            EncoderTG_input_ids = Q1_input_ids,
            EncoderTG_attention_mask = Q1_attention,
            TG_labels = GoldTags_input_ids,
            SUM_labels = GoldSummary_input_ids,
            return_dict = False
            )
        Summary, Tags, PLabel= Model_Output
        RQE_Loss = self.RQE_Loss_Func(
            PLabel.view(-1, PLabel.shape[-1]),
            Pair_Labels
            )
        SUM_Loss = self.SUM_Loss_Func(
            GoldSummary_input_ids,
            Summary,
            self.Model.SUM.config.pad_token_id,
            self.Model.SUM.config.vocab_size,
            self.tokenizer
            )
        TG_Loss = self.TG_Loss_Func(
            GoldTags_input_ids,
            Tags,
            self.Model.TG.config.pad_token_id,
            self.Model.TG.config.vocab_size,
            self.tokenizer
            )

        if iter == 0:
          Encoder_Loss = self.Coefficient['SUM'] * SUM_Loss +\
                         self.Coefficient['RQE'] * RQE_Loss +\
                         self.Coefficient['TG'] * TG_Loss
          self.manual_backward(Encoder_Loss)
          self.opt2.step()
          self.scheduler_Encoder.step()

        elif iter == 1:
          Decoder_Loss = self.Coefficient['SUM2'] * SUM_Loss +\
                         self.Coefficient['TG2'] * TG_Loss
          self.manual_backward(Decoder_Loss)
          self.opt3.step()
          self.scheduler_Decoder.step()

        elif iter == 2:
          RQE_Loss = self.Coefficient['RQE3'] * RQE_Loss
          self.manual_backward(RQE_Loss, retain_graph = True)
          self.opt1.step()

          SUM_Loss = self.Coefficient['SUM3'] * SUM_Loss
          self.manual_backward(SUM_Loss, retain_graph = True)
          self.opt4.step()

          TG_Loss = self.Coefficient['TG3'] * TG_Loss
          self.manual_backward(TG_Loss, retain_graph = True)
          self.opt5.step()

        self.log('train/rqe_loss', RQE_Loss.item(), on_step=True, on_epoch=True)
        self.log('train/sum_loss', SUM_Loss.item(), on_step=True, on_epoch=True)
        self.log('train/tg_loss', TG_Loss.item(), on_step=True, on_epoch=True)

        output =  {
            'Model_Output': Model_Output,
            'RQE_Loss': RQE_Loss,
            'SUM_Loss': SUM_Loss,
            'TG_Loss': TG_Loss
            }
        return output


    def test_step(self, batch, batch_idx):
      Q1_input_ids, Q1_attention, Q1Q2_input_ids, Q1Q2_attention,\
          Q1Tags_input_ids, Q1Tags_attention, GoldSummary_input_ids,\
            GoldTags_input_ids, Pair_Labels = batch

      summary_decoded = self.Model.SUM_generate2(
        tokenizer = self.tokenizer,
        input_ids = Q1Tags_input_ids,
        _max_length = 200,
        _min_length = 10,
        _num_beams = 4,
        _no_repeat_ngram_size = 3
        )
      tg_decoded = self.Model.TG_generate2(
        tokenizer = self.tokenizer,
        input_ids = Q1_input_ids,
        _max_length = 20,
        _min_length = 3,
        _num_beams = 4,
        _no_repeat_ngram_size = 3
        )
      [Scores_predicted, labels_predicted] = self.Model.RQE_predict(
          input_ids = Q1Q2_input_ids,
          attention_masks = Q1Q2_attention,
          )

      Q1_input_ids = torch.where(
          Q1_input_ids != -100,
          Q1_input_ids,
          self.Model.SUM.config.pad_token_id
          )
      Q1s = self.tokenizer.batch_decode(
          sequences = Q1_input_ids,
          skip_special_tokens = True,
          clean_up_tokenization_spaces = False
          )
      GoldSummary_input_ids = torch.where(
          GoldSummary_input_ids != -100,
          GoldSummary_input_ids,
          self.Model.SUM.config.pad_token_id
          )
      GoldSummaries = self.tokenizer.batch_decode(
          sequences = GoldSummary_input_ids,
          skip_special_tokens = True,
          clean_up_tokenization_spaces = False
          )
      GoldTags_input_ids = torch.where(
          GoldTags_input_ids != -100,
          GoldTags_input_ids,
          self.Model.SUM.config.pad_token_id
          )
      GoldTags = self.tokenizer.batch_decode(
          sequences = GoldTags_input_ids,
          skip_special_tokens = True,
          clean_up_tokenization_spaces = False
          )

      self.test_sum_metrics.update(summary_decoded, GoldSummaries)
      self.test_tg_metrics.update(tg_decoded, GoldTags)
      self.test_rqe_metrics.update(labels_predicted, Pair_Labels)


    def validation_step(self, batch, batch_idx):
      Q1_input_ids, Q1_attention, Q1Q2_input_ids, Q1Q2_attention,\
          Q1Tags_input_ids, Q1Tags_attention, GoldSummary_input_ids,\
            GoldTags_input_ids, Pair_Labels = batch

      with torch.no_grad():
        Model_Output = self.Model(
            EncoderRQE_input_ids = Q1Q2_input_ids,
            EncoderRQE_attention = Q1Q2_attention,
            EncoderSUM_input_ids = Q1Tags_input_ids,
            EncoderSUM_attention_mask = Q1Tags_attention,
            EncoderTG_input_ids = Q1_input_ids,
            EncoderTG_attention_mask = Q1_attention,
            TG_labels = GoldTags_input_ids,
            SUM_labels = GoldSummary_input_ids,
            return_dict = False
            )
        Summary, Tags, PLabel = Model_Output
        RQE_Loss = self.RQE_Loss_Func(
            PLabel.view(-1, PLabel.shape[-1]),
            Pair_Labels
            )
        SUM_Loss = self.SUM_Loss_Func(
            GoldSummary_input_ids,
            Summary,
            self.Model.SUM.config.pad_token_id,
            self.Model.SUM.config.vocab_size,
            self.tokenizer
            )
        TG_Loss = self.TG_Loss_Func(
            GoldTags_input_ids,
            Tags,
            self.Model.TG.config.pad_token_id,
            self.Model.TG.config.vocab_size,
            self.tokenizer
            )

        self.log('val/rqe_loss', RQE_Loss.item(), on_step=True, on_epoch=True)
        self.log('val/sum_loss', SUM_Loss.item(), on_step=True, on_epoch=True)
        self.log('val/tg_loss', TG_Loss.item(), on_step=True, on_epoch=True)

        output =  {
            'Model_Output': Model_Output,
            'RQE_Loss': RQE_Loss,
            'SUM_Loss': SUM_Loss,
            'TG_Loss': TG_Loss
            }
        return output


    def on_test_epoch_end(self):
      te_rqe_metrics = self.test_rqe_metrics.compute()
      te_sum_metrics = self.test_sum_metrics.compute()
      te_tg_metrics = self.test_tg_metrics.compute()

      self.log_dict(te_rqe_metrics, prog_bar=True)
      self.log('test_rouge1_sum(f)', te_sum_metrics['test_rouge1_fmeasure'])
      self.log('test_rouge2_sum(f)', te_sum_metrics['test_rouge2_fmeasure'])
      self.log('test_rougel_sum(f)', te_sum_metrics['test_rougeL_fmeasure'])
      self.log('test_rouge1_sum(r)', te_sum_metrics['test_rouge1_recall'])
      self.log('test_rouge2_sum(r)', te_sum_metrics['test_rouge2_recall'])
      self.log('test_rougel_sum(r)', te_sum_metrics['test_rougeL_recall'])
      self.log('test_rouge1_tg(f)', te_tg_metrics['test_rouge1_fmeasure'])
      self.log('test_rouge2_tg(f)', te_tg_metrics['test_rouge2_fmeasure'])
      self.log('test_rougel_tg(f)', te_tg_metrics['test_rougeL_fmeasure'])
      self.log('test_rouge1_tg(r)', te_tg_metrics['test_rouge1_recall'])
      self.log('test_rouge2_tg(r)', te_tg_metrics['test_rouge2_recall'])
      self.log('test_rougel_tg(r)', te_tg_metrics['test_rougeL_recall'])
      self.log('test_BS_score_sum(r)', te_sum_metrics['test_recall'].mean())
      self.log('test_BS_score_sum(f)', te_sum_metrics['test_f1'].mean())
      self.log('test_BS_score_tg(r)', te_tg_metrics['test_recall'].mean())
      self.log('test_BS_score_tg(f)', te_tg_metrics['test_f1'].mean())

      self.test_rqe_metrics.reset()
      self.test_sum_metrics.reset()
      self.test_tg_metrics.reset()


    def configure_optimizers(self):
      #  1.  Optimizer for BART Encoder module only
      opt_BART_Encoder = torch.optim.AdamW(
          self.Model.SUM.encoder.parameters(),
          lr = self.Model.learning_rate_Encoder,
          eps = self.opt_epsilon
          )
      params = list(self.Model.SUM.decoder.embed_tokens.parameters()) +\
               list(self.Model.SUM.decoder.embed_positions.parameters()) +\
               list(self.Model.SUM.decoder.layernorm_embedding.parameters()) +\
               list(self.Model.SUM.decoder.layers[0:3].parameters())

      #  2.  Optimizer for BART shared Decoder layers only
      opt_BART_Decoder = torch.optim.AdamW(
          params,
          lr = self.Model.learning_rate_Decoder,
          eps = self.opt_epsilon
          )

      #  3.  Optimizer for RQE module only
      opt_RQE = torch.optim.AdamW(
          self.Model.RQE.parameters(),
          lr = self.Model.learning_rate_RQE,
          eps = self.opt_epsilon
          )
      paramsSUM = list(self.Model.SUM.decoder.layers[3:6].parameters()) +\
                  list(self.Model.SUM_lm_head.parameters())

      #  4.  Optimizer for Summarization module only
      opt_SUM = torch.optim.AdamW(
          paramsSUM,
          lr = self.Model.learning_rate_SUM,
          eps = self.opt_epsilon
          )
      paramsTG = list(self.Model.TG.decoder.layers[3:6].parameters()) +\
                 list(self.Model.TG_lm_head.parameters())

      #  5.  Optimizer for Tag generation module only
      opt_TG = torch.optim.AdamW(
          paramsTG,
          lr = self.Model.learning_rate_TG,
          eps = self.opt_epsilon)

      self.Model.Freeze_Parameters(self.FreezeDec, self.FreezeEnc)
      return opt_RQE, opt_BART_Encoder, opt_BART_Decoder, opt_SUM, opt_TG


    def configure_scheduler(self, optimizer):
      total_steps = self.num_train_batches * self.max_epochs
      scheduler = get_linear_schedule_with_warmup(
          optimizer,
          num_warmup_steps = self.warmup,
          num_training_steps = total_steps
          )
      return scheduler