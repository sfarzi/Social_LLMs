# -*- coding: utf-8 -*-
"""RQE_head.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k8WprvAMnHmKK63QsA9BT3RYPI9UrGEH
"""

class NN_model_RQE(nn.Module):
  def __init__(self,embed_size, Dimensions, do_r, lr):
    super(NN_model_RQE, self).__init__()
    layers = []
    prev_size = embed_size

    for i, size in enumerate(Dimensions):
      layers.append(nn.Linear(prev_size, size))
      layers.append(nn.LeakyReLU())
      layers.append(nn.BatchNorm1d(size))
      layers.append(nn.Dropout(do_r))
      prev_size = size
    layers.append(nn.Softmax(dim=-1))
    self.layers = nn.Sequential(*layers)

  def forward(self, decoder_last_embd):
    logits = self.layers(decoder_last_embd)
    return logits